{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c060e895-5f45-4b1c-9fe3-9b193ab4a57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Collecting protobuf<3.20,>=3.9.2 (from tensorflow)\n",
      "  Downloading protobuf-3.19.6-cp310-cp310-win_amd64.whl.metadata (806 bytes)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from tensorflow) (1.48.2)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.29.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Downloading protobuf-3.19.6-cp310-cp310-win_amd64.whl (895 kB)\n",
      "   ---------------------------------------- 0.0/895.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 895.7/895.7 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 19.7 MB/s eta 0:00:00\n",
      "Installing collected packages: libclang, tensorflow-io-gcs-filesystem, protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "Successfully installed libclang-18.1.1 protobuf-3.19.6 tensorflow-io-gcs-filesystem-0.31.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5d55456-22e3-4206-b447-62e03d4492be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\jayas\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (2.10.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40f8b4a-5aaa-4581-9658-63bce28740b2",
   "metadata": {},
   "source": [
    "**Data Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83499492-a664-4068-8e7c-cf7097f13deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array,array_to_img,load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b835e194-a03c-4b14-9f8e-3dc8ea7171f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=40,\n",
    " width_shift_range=0.2,\n",
    " height_shift_range=0.2,\n",
    " shear_range=0.2,\n",
    " zoom_range=0.2,\n",
    " horizontal_flip=True,\n",
    " fill_mode='reflect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd028d0a-bfe1-4ca3-a69b-fe4e3b34e23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(r\"C:\\Users\\jayas\\Downloads\\IMG-20240317-WA0001.jpg\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5537a1d7-d65f-47ad-9ef9-c5b9b845594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f89fcc7d-28b3-4706-9aa5-a27695c9965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch in datagen.flow(x,batch_size=1,save_to_dir=r\"C:\\Users\\jayas\\OneDrive\\Desktop\\New folder\\Keras\\Images\",save_format=\"jpeg\",save_prefix=\"Naveen\"):\n",
    "    i += 1\n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d974c156-ed6c-42bd-aa0d-a67e522a0ac0",
   "metadata": {},
   "source": [
    "**Resnet50**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12fcceb4-c4ae-41c9-96d8-557ba423cbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 981ms/step\n",
      "1 : borzoi (0.59)\n",
      "2 : Irish_wolfhound (0.11)\n",
      "3 : groenendael (0.08)\n",
      "169\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input,decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "model = ResNet50(weights = \"imagenet\")\n",
    "image = image.load_img(r\"C:\\Users\\jayas\\Downloads\\download.jpeg\",target_size=(224,224))\n",
    "image_arr = img_to_array(image)\n",
    "inup_img = np.expand_dims(image_arr,axis=0)\n",
    "pross_inp = preprocess_input(inup_img)\n",
    "predictions = model.predict(pross_inp)\n",
    "decode_inp = decode_predictions(predictions,top = 3)[0]\n",
    "\n",
    "for i,(imagenet_id,label,score) in enumerate(decode_inp):\n",
    "    print(f'{i+1} : {label} ({score:.2f})')\n",
    "top_index = np.argmax(predictions[0])\n",
    "print(top_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb9d47d-18db-4923-be95-9128a45b358f",
   "metadata": {},
   "source": [
    "**Resnet50V2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7da4e5a8-fd58-4953-a621-2330011901a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 918ms/step\n",
      "1 : Appenzeller  0.51)\n",
      "2 : Border_collie  0.21)\n",
      "3 : Cardigan  0.17)\n",
      "240\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2,preprocess_input,decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "model = ResNet50V2(weights = \"imagenet\")\n",
    "image = image.load_img(r\"C:\\Users\\jayas\\Downloads\\download.jpeg\",target_size=(224,224))\n",
    "image_arr = img_to_array(image)\n",
    "image_dim = np.expand_dims(image_arr,axis=0)\n",
    "process_img = preprocess_input(image_dim)\n",
    "predictions = model.predict(process_img)\n",
    "decode_inp = decode_predictions(predictions,top = 3)[0]\n",
    "\n",
    "for i,(imagenet_id,label,score) in enumerate(decode_inp):\n",
    "    print(f'{i+1} : {label} {score: .2f})')\n",
    "\n",
    "top_index = np.argmax(predictions[0])\n",
    "print(top_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e3fd4e-ddcb-4ec7-8b44-75471f8c033d",
   "metadata": {},
   "source": [
    "**VGG16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a034acbc-35e8-4154-b04c-ee2dbf9ef560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 327ms/step\n",
      "1 : borzoi ( 0.80)\n",
      "2 : collie ( 0.09)\n",
      "3 : Afghan_hound ( 0.02)\n",
      "169\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16,preprocess_input,decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "model = VGG16(weights = \"imagenet\")\n",
    "image = image.load_img(r\"C:\\Users\\jayas\\Downloads\\download.jpeg\",target_size=(224,224))\n",
    "image_arr = img_to_array(image)\n",
    "inp_dim = np.expand_dims(image_arr,axis=0)\n",
    "inp_pross = preprocess_input(inp_dim)\n",
    "predictions = model.predict(inp_pross)\n",
    "decode_inp = decode_predictions(predictions,top = 3)[0]\n",
    "\n",
    "for i,(imagenet_id,label,score) in enumerate(decode_inp):\n",
    "    print(f'{i + 1} : {label} ({score: .2f})')\n",
    "top_index = np.argmax(predictions[0])\n",
    "print(top_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a04f52-b2c6-4ab8-87f6-9b57d37c6fb8",
   "metadata": {},
   "source": [
    "**VGG19**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "670a3c03-7597-4973-b097-7c48d08181e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1 collie ( 0.52)\n",
      "2 borzoi ( 0.10)\n",
      "3 Shetland_sheepdog ( 0.04)\n",
      "231\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19,preprocess_input,decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "model = VGG19(weights = \"imagenet\")\n",
    "image = image.load_img(r\"C:\\Users\\jayas\\Downloads\\download.jpeg\",target_size=(224,224))\n",
    "image_arr = img_to_array(image)\n",
    "inp_dim = np.expand_dims(image_arr,axis=0)\n",
    "inp_pros = preprocess_input(inp_dim)\n",
    "predictions = model.predict(inp_pros)\n",
    "decode_inp = decode_predictions(predictions,top = 3)[0]\n",
    "\n",
    "for i,(imagenet_id,label,score) in enumerate(decode_inp):\n",
    "    print(f'{i + 1} {label} ({score: .2f})')\n",
    "top_index = np.argmax(predictions[0])\n",
    "print(top_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b77952-1edf-4159-8d17-976cbb31a9be",
   "metadata": {},
   "source": [
    "**EEfficientNetV2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "830e89be-cce0-4a40-8cc4-b739e3309965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 15s 15s/step\n",
      "1 Border_collie ( 0.47)\n",
      "2 tabby ( 0.08)\n",
      "3 collie ( 0.08)\n",
      "232\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2L,preprocess_input,decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "model = EfficientNetV2L(weights = \"imagenet\")\n",
    "image = image.load_img(r\"C:\\Users\\jayas\\Downloads\\download.jpeg\",target_size=(480,480))\n",
    "image_arr = img_to_array(image)\n",
    "img_dim = np.expand_dims(image_arr,axis=0)\n",
    "img_pross = preprocess_input(img_dim)\n",
    "predictions = model.predict(img_pross)\n",
    "decode_img = decode_predictions(predictions,top=3)[0]\n",
    "for i,(imagenet_id,label,score) in enumerate(decode_img):\n",
    "    print(f'{i + 1} {label} ({score: .2f})')\n",
    "top_index = np.argmax(predictions[0])\n",
    "print(top_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a9c9d-014b-44cb-b78f-9d1ac143453a",
   "metadata": {},
   "source": [
    "**Nasnet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00ba22c3-3997-410b-a81d-626e5636c7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 13s 13s/step\n",
      "1 Border_collie ( 0.43)\n",
      "2 collie ( 0.32)\n",
      "3 Shetland_sheepdog ( 0.01)\n",
      "232\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.nasnet import NASNetLarge,preprocess_input,decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "model = NASNetLarge(weights = \"imagenet\")\n",
    "image = image.load_img(r\"C:\\Users\\jayas\\Downloads\\download.jpeg\",target_size=(331,331))\n",
    "image_arr = img_to_array(image)\n",
    "img_dim = np.expand_dims(image_arr,axis=0)\n",
    "img_pross = preprocess_input(img_dim)\n",
    "predictions = model.predict(img_pross)\n",
    "decode_img = decode_predictions(predictions,top=3)[0]\n",
    "for i,(imagenet_id,label,score) in enumerate(decode_img):\n",
    "    print(f'{i + 1} {label} ({score: .2f})')\n",
    "top_index = np.argmax(predictions[0])\n",
    "print(top_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39da862-7872-4abc-ac40-9c4415b9afc6",
   "metadata": {},
   "source": [
    "**Calculating Inference time and Storage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcd68ec8-4611-415b-a99d-deea123832a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23a255de-c592-4b5a-a4eb-59ccf0aa9501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002BB2A0089D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 812ms/step\n",
      "1 : borzoi (0.59)\n",
      "2 : Irish_wolfhound (0.11)\n",
      "3 : groenendael (0.08)\n",
      "169\n",
      "Inference Time: 1448.33 ms\n",
      "Size (MB): 97.80 MB\n",
      "Num_parameters : 25636712\n",
      "Model_depth : 177\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input,decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "start_time = time.time()\n",
    "model = ResNet50(weights = \"imagenet\")\n",
    "end_time = time.time()\n",
    "image = image.load_img(r\"C:\\Users\\jayas\\Downloads\\download.jpeg\",target_size=(224,224))\n",
    "image_arr = img_to_array(image)\n",
    "inup_img = np.expand_dims(image_arr,axis=0)\n",
    "pross_inp = preprocess_input(inup_img)\n",
    "predictions = model.predict(pross_inp)\n",
    "decode_inp = decode_predictions(predictions,top = 3)[0]\n",
    "\n",
    "for i,(imagenet_id,label,score) in enumerate(decode_inp):\n",
    "    print(f'{i+1} : {label} ({score:.2f})')\n",
    "top_index = np.argmax(predictions[0])\n",
    "print(top_index)\n",
    "\n",
    "inference_time_ms = (end_time- start_time) * 1000.0\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2) \n",
    "print(f\"Size (MB): {model_size_MB:.2f} MB\")\n",
    "\n",
    "num_parameters = model.count_params()\n",
    "model_depth = len(model.layers)\n",
    "\n",
    "print(f'Num_parameters : {num_parameters}')\n",
    "print(f'Model_depth : {model_depth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36880506-50f0-4936-ba36-778d3c615185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002BB2A00ACB0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 959ms/step\n",
      "1 : Appenzeller (0.51)\n",
      "2 : Border_collie (0.21)\n",
      "3 : Cardigan (0.17)\n",
      "240\n",
      "Inference Time: 1513.66 ms\n",
      "Size (MB): 97.71 MB\n",
      "Num_parameters : 25613800\n",
      "Model_depth : 192\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2,preprocess_input,decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "start_time = time.time()\n",
    "model = ResNet50V2(weights = \"imagenet\")\n",
    "end_time = time.time()\n",
    "image = image.load_img(r\"C:\\Users\\jayas\\Downloads\\download.jpeg\",target_size=(224,224))\n",
    "image_arr = img_to_array(image)\n",
    "inup_img = np.expand_dims(image_arr,axis=0)\n",
    "pross_inp = preprocess_input(inup_img)\n",
    "predictions = model.predict(pross_inp)\n",
    "decode_inp = decode_predictions(predictions,top = 3)[0]\n",
    "\n",
    "for i,(imagenet_id,label,score) in enumerate(decode_inp):\n",
    "    print(f'{i+1} : {label} ({score:.2f})')\n",
    "top_index = np.argmax(predictions[0])\n",
    "print(top_index)\n",
    "\n",
    "inference_time_ms = (end_time- start_time) * 1000.0\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2) \n",
    "print(f\"Size (MB): {model_size_MB:.2f} MB\")\n",
    "\n",
    "num_parameters = model.count_params()\n",
    "model_depth = len(model.layers)\n",
    "\n",
    "print(f'Num_parameters : {num_parameters}')\n",
    "print(f'Model_depth : {model_depth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d571e432-2920-4cff-9da3-8a93b3bb88d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1 : borzoi (0.80)\n",
      "2 : collie (0.09)\n",
      "3 : Afghan_hound (0.02)\n",
      "169\n",
      "Inference Time: 7154.30 ms\n",
      "Size (MB): 527.79 MB\n",
      "Num_parameters : 138357544\n",
      "Model_depth : 23\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications.vgg16 import VGG16,preprocess_input,decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "start_time = time.time()\n",
    "model = VGG16(weights = \"imagenet\")\n",
    "end_time = time.time()\n",
    "image = image.load_img(r\"C:\\Users\\jayas\\Downloads\\download.jpeg\",target_size=(224,224))\n",
    "image_arr = img_to_array(image)\n",
    "inup_img = np.expand_dims(image_arr,axis=0)\n",
    "pross_inp = preprocess_input(inup_img)\n",
    "predictions = model.predict(pross_inp)\n",
    "decode_inp = decode_predictions(predictions,top = 3)[0]\n",
    "\n",
    "for i,(imagenet_id,label,score) in enumerate(decode_inp):\n",
    "    print(f'{i+1} : {label} ({score:.2f})')\n",
    "top_index = np.argmax(predictions[0])\n",
    "print(top_index)\n",
    "\n",
    "inference_time_ms = (end_time- start_time) * 1000.0\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2) \n",
    "print(f\"Size (MB): {model_size_MB:.2f} MB\")\n",
    "\n",
    "num_parameters = model.count_params()\n",
    "model_depth = len(model.layers)\n",
    "\n",
    "print(f'Num_parameters : {num_parameters}')\n",
    "print(f'Model_depth : {model_depth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dbd8cdf-eb88-4114-81fb-975f28f448fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 453ms/step\n",
      "1 : collie (0.52)\n",
      "2 : borzoi (0.10)\n",
      "3 : Shetland_sheepdog (0.04)\n",
      "231\n",
      "Inference Time: 2627.43 ms\n",
      "Size (MB): 548.05 MB\n",
      "Num_parameters : 143667240\n",
      "Model_depth : 26\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications.vgg19 import VGG19,preprocess_input,decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "start_time = time.time()\n",
    "model = VGG19(weights = \"imagenet\")\n",
    "end_time = time.time()\n",
    "image = image.load_img(r\"C:\\Users\\jayas\\Downloads\\download.jpeg\",target_size=(224,224))\n",
    "image_arr = img_to_array(image)\n",
    "inup_img = np.expand_dims(image_arr,axis=0)\n",
    "pross_inp = preprocess_input(inup_img)\n",
    "predictions = model.predict(pross_inp)\n",
    "decode_inp = decode_predictions(predictions,top = 3)[0]\n",
    "\n",
    "for i,(imagenet_id,label,score) in enumerate(decode_inp):\n",
    "    print(f'{i+1} : {label} ({score:.2f})')\n",
    "top_index = np.argmax(predictions[0])\n",
    "print(top_index)\n",
    "\n",
    "inference_time_ms = (end_time- start_time) * 1000.0\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2) \n",
    "print(f\"Size (MB): {model_size_MB:.2f} MB\")\n",
    "\n",
    "num_parameters = model.count_params()\n",
    "model_depth = len(model.layers)\n",
    "\n",
    "print(f'Num_parameters : {num_parameters}')\n",
    "print(f'Model_depth : {model_depth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed218eec-9d09-4080-8889-306bc7bb96b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step\n",
      "1 : Border_collie (0.47)\n",
      "2 : tabby (0.08)\n",
      "3 : collie (0.08)\n",
      "232\n",
      "Inference Time: 9518.67 ms\n",
      "Size (MB): 454.06 MB\n",
      "Num_parameters : 119027848\n",
      "Model_depth : 1031\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2L,preprocess_input,decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "start_time = time.time()\n",
    "model = EfficientNetV2L(weights = \"imagenet\")\n",
    "end_time = time.time()\n",
    "image = image.load_img(r\"C:\\Users\\jayas\\Downloads\\download.jpeg\",target_size=(480,480))\n",
    "image_arr = img_to_array(image)\n",
    "inup_img = np.expand_dims(image_arr,axis=0)\n",
    "pross_inp = preprocess_input(inup_img)\n",
    "predictions = model.predict(pross_inp)\n",
    "decode_inp = decode_predictions(predictions,top = 3)[0]\n",
    "\n",
    "for i,(imagenet_id,label,score) in enumerate(decode_inp):\n",
    "    print(f'{i+1} : {label} ({score:.2f})')\n",
    "top_index = np.argmax(predictions[0])\n",
    "print(top_index)\n",
    "\n",
    "inference_time_ms = (end_time- start_time) * 1000.0\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2) \n",
    "print(f\"Size (MB): {model_size_MB:.2f} MB\")\n",
    "\n",
    "num_parameters = model.count_params()\n",
    "model_depth = len(model.layers)\n",
    "\n",
    "print(f'Num_parameters : {num_parameters}')\n",
    "print(f'Model_depth : {model_depth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebea2e3b-b277-43a2-8955-5f183f2140c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step\n",
      "1 : Border_collie (0.43)\n",
      "2 : collie (0.32)\n",
      "3 : Shetland_sheepdog (0.01)\n",
      "232\n",
      "Inference Time: 7996.85 ms\n",
      "Size (MB): 339.32 MB\n",
      "Num_parameters : 88949818\n",
      "Model_depth : 1041\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.nasnet import NASNetLarge,preprocess_input,decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "start_time = time.time()\n",
    "model = NASNetLarge(weights = \"imagenet\")\n",
    "end_time = time.time()\n",
    "image = image.load_img(r\"C:\\Users\\jayas\\Downloads\\download.jpeg\",target_size=(331,331))\n",
    "image_arr = img_to_array(image)\n",
    "inup_img = np.expand_dims(image_arr,axis=0)\n",
    "pross_inp = preprocess_input(inup_img)\n",
    "predictions = model.predict(pross_inp)\n",
    "decode_inp = decode_predictions(predictions,top = 3)[0]\n",
    "\n",
    "for i,(imagenet_id,label,score) in enumerate(decode_inp):\n",
    "    print(f'{i+1} : {label} ({score:.2f})')\n",
    "top_index = np.argmax(predictions[0])\n",
    "print(top_index)\n",
    "\n",
    "inference_time_ms = (end_time- start_time) * 1000.0\n",
    "print(f\"Inference Time: {inference_time_ms:.2f} ms\")\n",
    "\n",
    "model_size_MB = model.count_params() * 4 / (1024 ** 2) \n",
    "print(f\"Size (MB): {model_size_MB:.2f} MB\")\n",
    "\n",
    "num_parameters = model.count_params()\n",
    "model_depth = len(model.layers)\n",
    "\n",
    "print(f'Num_parameters : {num_parameters}')\n",
    "print(f'Model_depth : {model_depth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030e6d68-81a7-4f75-a5c5-d3721d9843f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
